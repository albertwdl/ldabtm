{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Albert\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "d:\\Anaconda\\lib\\site-packages\\pyLDAvis\\_prepare.py:243: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本次生成了文件： top-topic-words.csv document-distribution.csv document-lda-visualization.html\n"
     ]
    }
   ],
   "source": [
    "import pyLDAvis.sklearn\n",
    "import pyLDAvis\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import re\n",
    "import os\n",
    "\n",
    "# 待做 LDA 的文本 csv 文件，可以是本地文件，也可以是远程文件，一定要保证它是存在的！！！！\n",
    "# source_csv_path = 'answers.csv'\n",
    "source_csv_path = './lad.csv'\n",
    "# 文本 csv 文件里面文本所处的列名,注意这里一定要填对，要不然会报错的！！！\n",
    "# document_column_name = '回答内容'\n",
    "document_column_name = 'reviewinfo'\n",
    "# 输出主题词的文件路径\n",
    "top_words_csv_path = 'top-topic-words.csv'\n",
    "# 输出各文档所属主题的文件路径\n",
    "predict_topic_csv_path = 'document-distribution.csv'\n",
    "# 可视化 html 文件路径\n",
    "html_path = 'document-lda-visualization.html'\n",
    "# 选定的主题数\n",
    "n_topics = 5\n",
    "# 要输出的每个主题的前 n_top_words 个主题词数\n",
    "n_top_words = 20\n",
    "# 去除无意义字符的正则表达式\n",
    "pattern = u'[\\\\s\\\\d,.<>/?:;\\'\\\"[\\\\]{}()\\\\|~!\\t\"@#$%^&*\\\\-_=+，。\\n《》、？：；“”‘’｛｝【】（）…￥！—┄－]+'\n",
    "\n",
    "def top_words_data_frame(model: LatentDirichletAllocation,\n",
    "                         tf_idf_vectorizer: TfidfVectorizer,\n",
    "                         n_top_words: int) -> pd.DataFrame:\n",
    "    '''\n",
    "    求出每个主题的前 n_top_words 个词\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : sklearn 的 LatentDirichletAllocation \n",
    "    tf_idf_vectorizer : sklearn 的 TfidfVectorizer\n",
    "    n_top_words :前 n_top_words 个主题词\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    DataFrame: 包含主题词分布情况\n",
    "    '''\n",
    "    rows = []\n",
    "    feature_names = tf_idf_vectorizer.get_feature_names_out()\n",
    "    for topic in model.components_:\n",
    "        top_words = [feature_names[i]\n",
    "                     for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "        rows.append(top_words)\n",
    "    columns = [f'topic word {i+1}' for i in range(n_top_words)]\n",
    "    df = pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def predict_to_data_frame(model: LatentDirichletAllocation, X: np.ndarray) -> pd.DataFrame:\n",
    "    '''\n",
    "    求出文档主题概率分布情况\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : sklearn 的 LatentDirichletAllocation \n",
    "    X : 词向量矩阵\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    DataFrame: 包含主题词分布情况\n",
    "    '''\n",
    "    matrix = model.transform(X)\n",
    "    columns = [f'P(topic {i+1})' for i in range(len(model.components_))]\n",
    "    df = pd.DataFrame(matrix, columns=columns)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = (\n",
    "    pd.read_csv(\n",
    "        source_csv_path,\n",
    "        encoding='utf-8-sig')\n",
    "    .drop_duplicates()\n",
    "    .rename(columns={\n",
    "        document_column_name: 'text'\n",
    "    }))\n",
    "# 设置停用词集合\n",
    "stop_words_set = set(['你', '我'])\n",
    "# 去重、去缺失、分词\n",
    "df['cut'] = (\n",
    "    df['text']\n",
    "    .apply(lambda x: str(x))\n",
    "    .apply(lambda x: re.sub(pattern, ' ', x))\n",
    "    .apply(lambda x: \" \".join([word for word in jieba.lcut(x) if word not in stop_words_set]))\n",
    ")\n",
    "\n",
    "# 构造 tf-idf\n",
    "tf_idf_vectorizer = TfidfVectorizer(dtype=np.float32)\n",
    "tf_idf = tf_idf_vectorizer.fit_transform(df['cut'])\n",
    "\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=n_topics,\n",
    "    max_iter=50,\n",
    "    learning_method='online',\n",
    "    learning_offset=50,\n",
    "    random_state=0)\n",
    "\n",
    "# 使用 tf_idf 语料训练 lda 模型\n",
    "lda.fit(tf_idf)\n",
    "\n",
    "# 计算 n_top_words 个主题词\n",
    "top_words_df = top_words_data_frame(lda, tf_idf_vectorizer, n_top_words)\n",
    "\n",
    "# 保存 n_top_words 个主题词到 csv 文件中\n",
    "top_words_df.to_csv(top_words_csv_path, encoding='utf-8-sig', index=None)\n",
    "\n",
    "# 转 tf_idf 为数组，以便后面使用它来对文本主题概率分布进行计算\n",
    "X = tf_idf.toarray()\n",
    "# X = np.asarray(tf_idf.astype(np.float16).todense(), dtype=np.float16)\n",
    "\n",
    "# 计算完毕主题概率分布情况\n",
    "predict_df = predict_to_data_frame(lda, X)\n",
    "\n",
    "# 保存文本主题概率分布到 csv 文件中\n",
    "predict_df.to_csv(predict_topic_csv_path, encoding='utf-8-sig', index=None)\n",
    "\n",
    "# 使用 pyLDAvis 进行可视化\n",
    "data = pyLDAvis.sklearn.prepare(lda, tf_idf, tf_idf_vectorizer)\n",
    "pyLDAvis.save_html(data, html_path)\n",
    "# 清屏\n",
    "os.system('clear')\n",
    "# 浏览器打开 html 文件以查看可视化结果\n",
    "os.system(f'start {html_path}')\n",
    "\n",
    "print('本次生成了文件：',\n",
    "      top_words_csv_path,\n",
    "      predict_topic_csv_path,\n",
    "      html_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 topic words for each topic are saved in 'top-topic-words.csv'.\n",
      "Topic probability distributions are saved in 'distribution.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim import corpora, models\n",
    "\n",
    "# 读取csv文件\n",
    "df = pd.read_csv(\"lda.csv\")\n",
    "\n",
    "# 提取“reviewinfo”列中的文本数据，并将所有数据类型转换为字符串类型\n",
    "texts = [str(document) for document in df['reviewinfo'].tolist()]\n",
    "\n",
    "# 建立文本语料库\n",
    "texts = [[word for word in document.lower().split()] for document in texts]\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# 训练LDA模型\n",
    "num_topics = 10  # 设置主题数量\n",
    "lda_model = models.LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics)\n",
    "\n",
    "# 保存每个主题的top 10 topic words到文件\n",
    "topic_words = []\n",
    "for i, topic in lda_model.show_topics(num_topics=num_topics, formatted=False):\n",
    "    top_words = [word[0] for word in topic[:10]]\n",
    "    topic_words.append(top_words)\n",
    "    with open(\"top-topic-words.csv\", \"a\") as f:\n",
    "        f.write(f\"Topic {i}: {', '.join(top_words)}\\n\")\n",
    "\n",
    "# 保存主题概率分布到文件\n",
    "distributions = []\n",
    "for i in range(num_topics):\n",
    "    prob_distribution = lda_model.get_topic_terms(i, topn=10)\n",
    "    distribution = [round(prob[1], 2) for prob in prob_distribution]\n",
    "    distributions.append(distribution)\n",
    "    with open(\"distribution.csv\", \"a\") as f:\n",
    "        f.write(f\"Topic {i}: {', '.join(map(str, distribution))}\\n\")\n",
    "\n",
    "# 打印结果\n",
    "print(\"Top 10 topic words for each topic are saved in 'top-topic-words.csv'.\")\n",
    "print(\"Topic probability distributions are saved in 'distribution.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
